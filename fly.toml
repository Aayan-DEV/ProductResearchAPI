# Fly.io app configuration for AI Keywords Etsy API

# Set to your desired app name (must be unique on Fly)
app = "ai-keywords-etsy-api"
# Choose a region close to your users; "iad" is US East by default
primary_region = "iad"

[build]
  dockerfile = "Dockerfile"

[env]
  # Matches the Dockerfile and uvicorn fallback in main.py
  PORT = "8080"
  # Persist model and outputs under the mounted volume
  MODEL_DIR = "/data/models"
  ETO_OUTPUT_DIR = "/data/outputs"
  AI_USERS_DIR = "/data/users"

# Persist data and the downloaded GGUF model
[[mounts]]
  source = "data"
  destination = "/data"

# Machine sizing â€” adjust if the model or workload needs more memory/CPU
[vm]
  cpu_kind = "performance"
  cpus = 2
  memory_mb = 2048

# Public HTTP service
[[services]]
  protocol = "tcp"
  internal_port = 8080

  [services.concurrency]
    type = "connections"
    soft_limit = 40
    hard_limit = 50

  # HTTP ports exposed publicly
  [[services.ports]]
    port = 80
    handlers = ["http"]
  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  # Health check hitting your /ready endpoint
  [[services.http_checks]]
    path = "/ready"
    method = "get"
    interval = "15s"
    timeout = "5s"
    grace_period = "30s"